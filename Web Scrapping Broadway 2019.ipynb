{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import urllib\n",
    "import math\n",
    "import copy\n",
    "import pandas as pd\t\n",
    "import numpy as np\n",
    "import datetime\n",
    "from bs4 import BeautifulSoup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################\n",
    "###################### Prepare Functions ############################\n",
    "#####################################################################\n",
    "\n",
    "class html_tables(object):\n",
    "    \n",
    "    def __init__(self, url):\n",
    "        \n",
    "        self.url      = url\n",
    "        self.r        = requests.get(self.url)\n",
    "        self.url_soup = BeautifulSoup(self.r.text)\n",
    "        \n",
    "    def read(self):\n",
    "        \n",
    "        self.tables      = []\n",
    "        self.tables_html = self.url_soup.find_all(\"table\")\n",
    "        \n",
    "        # Parse each table\n",
    "        for n in range(0, len(self.tables_html)):\n",
    "            \n",
    "            n_cols = 0\n",
    "            n_rows = 0\n",
    "            \n",
    "            for row in self.tables_html[n].find_all(\"tr\"):\n",
    "                col_tags = row.find_all([\"td\", \"th\"])\n",
    "                if len(col_tags) > 0:\n",
    "                    n_rows += 1\n",
    "                    if len(col_tags) > n_cols:\n",
    "                        n_cols = len(col_tags)\n",
    "            \n",
    "            # Create dataframe\n",
    "            df = pd.DataFrame(index = range(0, n_rows), columns = range(0, n_cols))\n",
    "            \n",
    "            # Create list to store rowspan values \n",
    "            skip_index = [0 for i in range(0, n_cols)]\n",
    "            \n",
    "            # Start by iterating over each row in this table...\n",
    "            row_counter = 0\n",
    "            for row in self.tables_html[n].find_all(\"tr\"):\n",
    "                \n",
    "                # Skip row if it's blank\n",
    "                if len(row.find_all([\"td\", \"th\"])) == 0:\n",
    "                    next\n",
    "                \n",
    "                else:\n",
    "                    \n",
    "                    # Get all cells containing data in this row\n",
    "                    columns = row.find_all([\"td\", \"th\"])\n",
    "                    col_dim = []\n",
    "                    row_dim = []\n",
    "                    col_dim_counter = -1\n",
    "                    row_dim_counter = -1\n",
    "                    col_counter = -1\n",
    "                    this_skip_index = copy.deepcopy(skip_index)\n",
    "                    \n",
    "                    for col in columns:\n",
    "                        \n",
    "                        # Determine cell dimensions\n",
    "                        colspan = col.get(\"colspan\")\n",
    "                        if colspan is None:\n",
    "                            col_dim.append(1)\n",
    "                        else:\n",
    "                            col_dim.append(int(colspan))\n",
    "                        col_dim_counter += 1\n",
    "                            \n",
    "                        rowspan = col.get(\"rowspan\")\n",
    "                        if rowspan is None:\n",
    "                            row_dim.append(1)\n",
    "                        else:\n",
    "                            row_dim.append(int(rowspan))\n",
    "                        row_dim_counter += 1\n",
    "                            \n",
    "                        # Adjust column counter\n",
    "                        if col_counter == -1:\n",
    "                            col_counter = 0  \n",
    "                        else:\n",
    "                            col_counter = col_counter + col_dim[col_dim_counter - 1]\n",
    "                            \n",
    "                        while skip_index[col_counter] > 0:\n",
    "                            col_counter += 1\n",
    "\n",
    "                        # Get cell contents  \n",
    "                        cell_data = col.get_text()\n",
    "                        \n",
    "                        # Insert data into cell\n",
    "                        df.iat[row_counter, col_counter] = cell_data\n",
    "\n",
    "                        # Record column skipping index\n",
    "                        if row_dim[row_dim_counter] > 1:\n",
    "                            this_skip_index[col_counter] = row_dim[row_dim_counter]\n",
    "                \n",
    "                # Adjust row counter \n",
    "                row_counter += 1\n",
    "                \n",
    "                # Adjust column skipping index\n",
    "                skip_index = [i - 1 if i > 0 else i for i in this_skip_index]\n",
    "\n",
    "            # Append dataframe to list of tables\n",
    "            self.tables.append(df)\n",
    "        \n",
    "        return(self.tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################\n",
    "################# Scrap Information from Webpages ###################\n",
    "#####################################################################\n",
    "\n",
    "# Select all the Sundays of 2019\n",
    "def allsundays(year):\n",
    "    return pd.date_range(start=str(year), end=str(year+1), \n",
    "                         freq='W-SUN').strftime('%Y-%m-%d').tolist()\n",
    "sunday2019 = list(allsundays(2019))\n",
    "\n",
    "# Scrap the information of all broadway shows in 2019\n",
    "data = pd.DataFrame()\n",
    "for week in sunday2019:\n",
    "    url = \"https://www.playbill.com/grosses?week=\"+week\n",
    "#    request = requests.get(url)\n",
    "#    if request.status_code == 200:     # Check if the url exists\n",
    "    df = html_tables(url).read()[0]\n",
    "    df['Week'] = week\n",
    "    data = data.append(df)\n",
    "\n",
    "data.to_csv(\"broadwaydata2019.csv\", index=False)\n",
    "data.isnull().values.any() # None null "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################\n",
    "################ Processing Web Scraped Information #################\n",
    "#####################################################################\n",
    "\n",
    "listData = data.iloc[:, 0:len(data.columns)-1]\n",
    "\n",
    "for i in range(len(listData.columns)):\n",
    "    listData.iloc[:,i] = listData.iloc[:,i].str.split('\\n')\n",
    "\n",
    "Broadway2019 = pd.concat([\n",
    "    listData.iloc[:,0].apply(pd.Series).iloc[:,[1,2]],\n",
    "    listData.iloc[:,1].apply(pd.Series).iloc[:,[1,2]],\n",
    "    listData.iloc[:,2].apply(pd.Series).iloc[:,1],\n",
    "    listData.iloc[:,3].apply(pd.Series).iloc[:,[1,2]], \n",
    "    listData.iloc[:,4].apply(pd.Series).iloc[:,[1,2]], \n",
    "    listData.iloc[:,5].apply(pd.Series).iloc[:,[1,2]],\n",
    "    listData.iloc[:,6].apply(pd.Series).iloc[:,1], \n",
    "    listData.iloc[:,7].apply(pd.Series).iloc[:,1]], \n",
    "    axis=1, ignore_index=True) \n",
    "\n",
    "Broadway2019.columns = [\"Show Name\", \"Theatre\", \"Gross\", \"Potential Gross\", \"Gross Diff\", \n",
    "                        \"Avg Ticket Price\", \"Top Ticket Price\", \"Seats Sold\", \"Seats in the Theatre\",\n",
    "                        \"Performances\", \"Previews\", \"Capacity\", \"Capacity Diff\"]\n",
    "\n",
    "Broadway2019['Week'] = data[\"Week\"]\n",
    "Broadway2019['Month'] = pd.DatetimeIndex(Broadway2019['Week']).month \n",
    "Broadway2019.loc[(Broadway2019['Month']==1) | (Broadway2019['Month']==2), 'Season'] = 'Winter'\n",
    "Broadway2019.loc[(Broadway2019['Month']==3) | (Broadway2019['Month']==4), 'Season'] = 'Spring'\n",
    "Broadway2019.loc[(Broadway2019['Month']==5) | (Broadway2019['Month']==6) | (Broadway2019['Month']==7), 'Season'] = 'Summer'\n",
    "Broadway2019.loc[(Broadway2019['Month']==8) | (Broadway2019['Month']==9) | (Broadway2019['Month']==10), 'Season'] = 'Fall'\n",
    "Broadway2019.loc[(Broadway2019['Month']==11) | (Broadway2019['Month']==12), 'Season'] = 'Holiday'\n",
    "\n",
    "Broadway2019.isnull().values.any() # None null \n",
    "\n",
    "Broadway2019.to_csv(\"broadway2019.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
